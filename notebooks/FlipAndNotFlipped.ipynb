{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can we both flip and not flip in a single model?\n",
    "\n",
    "So, this Notebook explores the possible solutions to our left/right hand weakness of our static model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First part deals with flipped/not flipped images\n",
    "\n",
    "This is a little cursed, flipped simply means we ran cv.flip(img, 1), to horizontally flip the image before giving it to MediaPipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Every letters gets an extra class for flipped/not flipped\n",
    "\n",
    "First part will make it so:\n",
    "\n",
    "That is every class (letter from alphabet) there will be a flipped and not.\n",
    "\n",
    "\n",
    "So for the letter B:\n",
    "- B_flip and\n",
    "- B_notflip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sign.training.load_data.StaticLandmarkLoader import StaticLandmarkLoader, TrainingData\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "BACKEND_MODEL = Path().cwd().parent.joinpath(\"backend\",\"model\")\n",
    "NOT_FLIPPED = BACKEND_MODEL.joinpath(\"NOT_FLIPPED_keypoints_from_data.csv\")\n",
    "FLIPPED = BACKEND_MODEL.joinpath(\"FLIPPED_keypoints_from_data.csv\")\n",
    "\n",
    "loader = StaticLandmarkLoader()\n",
    "nf = loader.load_training_data(str(NOT_FLIPPED.absolute()))\n",
    "yf = loader.load_training_data(str(FLIPPED.absolute()))\n",
    "\n",
    "def add_flipped(list, is_flipped: bool):\n",
    "    \"\"\"Adds the flipped name onto the label of the data\"\"\"\n",
    "    return map(lambda label: label + (\"_1\" if is_flipped else \"_0\"), list)\n",
    "\n",
    "def concat(*lists):\n",
    "    res = []\n",
    "    for l in lists:\n",
    "        res = res + list(l)\n",
    "    return res\n",
    "\n",
    "def train_test_split_concat(data, labels):\n",
    "    zipped = list(zip(data, labels))\n",
    "    train_set, test_set = train_test_split(zipped, test_size=0.2, random_state=42)\n",
    "\n",
    "    lnds_train, labels_train = list(zip(*train_set))\n",
    "    lnds_test, labels_test = list(zip(*test_set))\n",
    "    return lnds_train, labels_train, lnds_test, labels_test\n",
    "\n",
    "#Prepare training (and test data) that have had their flipped status added to their label\n",
    "combined_landmarks = concat(nf.landmarks_train,\n",
    "                            nf.landmarks_test,\n",
    "                            yf.landmarks_train,\n",
    "                            yf.landmarks_test)\n",
    "combined_labels = concat(add_flipped(nf.labels_train, False), \n",
    "                         add_flipped(nf.labels_test, False), \n",
    "                         add_flipped(yf.labels_train, True), \n",
    "                         add_flipped(yf.labels_test, True))\n",
    "\n",
    "lnds_train, labels_train, lnds_test, labels_test = train_test_split_concat(combined_landmarks, combined_labels)\n",
    "len(lnds_train), len(lnds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the classifier - naive approach with every letter getting a left/right class\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "classifier = make_pipeline(StandardScaler(),\n",
    "                           SVC(kernel=\"poly\", degree=3, coef0=1, C=1))\n",
    "classifier.fit(lnds_train, labels_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "predictions = classifier.predict(lnds_test)\n",
    "print(classification_report(labels_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#predictions = classifier.predict(lnds_test)\n",
    "ConfusionMatrixDisplay.from_predictions(labels_test, predictions)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Instead of a separate class, we insert an extra feature to mark left / right\n",
    "\n",
    "So, at the end of a \"sign\", that is after the last landmark (42th value, that is the last z of the 21st landmark) insert either a 1 (flipped) or 0 (not flipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Let's try to append an 0 or 1 to the train_data\n",
    "    # insert a 0 or 1 after each 42th float to mark wether it is flipped or not\n",
    "def insert_at_nth(arr:np.ndarray, N:int, insert:float):\n",
    "    arr2 = arr.flatten()\n",
    "    return np.append(np.insert(arr2, range(N, len(arr2), N), insert), 0).reshape((-1, N + 1))\n",
    "\n",
    "N = 42\n",
    "combined_landmarks = concat(insert_at_nth(nf.landmarks_train, N, 0),\n",
    "                            insert_at_nth(nf.landmarks_test, N, 0),\n",
    "                            insert_at_nth(yf.landmarks_train, N, 1),\n",
    "                            insert_at_nth(yf.landmarks_test, N,1))\n",
    "combined_labels = concat(nf.labels_train,\n",
    "                         nf.labels_test, \n",
    "                         yf.labels_train,\n",
    "                         yf.labels_test)\n",
    "lnds_train, labels_train, lnds_test, labels_test = train_test_split_concat(combined_landmarks, combined_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "classifier_extra_feature = make_pipeline(StandardScaler(),\n",
    "                                         SVC(kernel=\"poly\", degree=3, coef0=1, C=1))\n",
    "classifier_extra_feature.fit(lnds_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "predictions = classifier_extra_feature.predict(lnds_test)\n",
    "print(classification_report(labels_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now test the two different approaches against our homemade data for 'U'**\n",
    "\n",
    "First, read in the data from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lnds_stest, labels_stest = loader.load_test_data(\"bing_bong.csv\")\n",
    "labels_stest_with_feature = list(map(lambda x: x.split(\"_\")[0], labels_stest))\n",
    "\n",
    "lnds_stest2:np.ndarray = lnds_stest\n",
    "for idx, label in enumerate(labels_stest):\n",
    "    l, hand = label.split(\"_\")\n",
    "    idex = (idx+1) * 42\n",
    "    if hand.capitalize() == \"LEFT\":\n",
    "        lnds_stest2 = np.insert(lnds_stest2, idex, 0)\n",
    "    else:\n",
    "        lnds_stest2 = np.insert(lnds_stest2, idex, 1)\n",
    "#print(lnds_stest2.reshape((-1, 43)))\n",
    "lnds_stest2 = lnds_stest2.reshape((-1,43))\n",
    "\n",
    "#lnds_stest_with_feature = insert_at_nth(np.array(lnds_stest), N, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's investigate the one with an extra feature:\n",
    "predictions_U_left_right = classifier_extra_feature.predict(lnds_stest2)\n",
    "print(classification_report(labels_stest_with_feature, predictions_U_left_right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's invistage the model where (not) flipped get different classes\n",
    "def mapper(x:str):\n",
    "    label, hand = x.split(\"_\")\n",
    "    return label + (\"_1\" if hand == \"RIGHT\" else \"_0\")\n",
    "\n",
    "labels_extra_classes = list(map(mapper, labels_stest))\n",
    "predictions_U_left_right = classifier.predict(lnds_stest)\n",
    "print(classification_report(labels_extra_classes, predictions_U_left_right))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What if we instead use right/left from mp?\n",
    "\n",
    "Okay, so for this scenario we will append to our ouput csv (output from mediapipe), the handedness that MediaPipe provides.\n",
    "Meaning, every \"sign\" in our training data will be marked as either having been done by a \"right\" or \"left\" hand.\n",
    "\n",
    "\n",
    "The first model using right/left from MediaPipe will use the extra feature approach. (I believe that one had the best results from the earlier flipped/not-flipped testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sign.training.load_data.StaticLandmarkLoader import StaticLandmarkLoader\n",
    "import numpy as np\n",
    "loader = StaticLandmarkLoader()\n",
    "td = loader.load_handed_training_data(file_path=\"../backend/model/handedness_keypoints_from_data.csv\")\n",
    "x_train, y_train, x_test, y_test, h_train, h_test = td\n",
    "\n",
    "if h_train is None or h_test is None:\n",
    "    raise ValueError(f\"Something is empty that shouldn't be\")\n",
    "\n",
    "def append_handedness(xs:np.ndarray, hands:np.ndarray):\n",
    "    res = []\n",
    "    for i in range(len(xs)):\n",
    "        res.append(np.append(xs[i], 1 if hands[i] == \"right\" else 0))\n",
    "    return np.array(res).reshape((-1,43))\n",
    "\n",
    "x_train = append_handedness(x_train, h_train)\n",
    "x_test = append_handedness(x_test, h_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train a model on it.\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "classifier_rl = make_pipeline(StandardScaler(),\n",
    "                              SVC(kernel=\"poly\", degree=3, coef0=1, C=1))\n",
    "classifier_rl.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "preds = classifier_rl.predict(x_test)\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_stest(lnds_stest, labels_stest, hand:str = \"\"):\n",
    "    zipped = zip(lnds_stest, labels_stest)\n",
    "    if hand:\n",
    "        return zip(*list(filter(lambda x: x[1].split(\"_\")[1] == hand,zipped)))\n",
    "    else:\n",
    "        return zip(*zipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lnds_stest, labels_stest = loader.load_test_data(\"bing_bong.csv\")\n",
    "lnds_stest, labels_stest = filter_stest(lnds_stest, labels_stest, \"\")\n",
    "stest_handed = np.array(list(map(lambda x: x.split(\"_\")[1].lower(),labels_stest)))\n",
    "#stest_handed = np.array(list(map(lambda x: \"left\" if x.lower() == \"right\" else \"right\", stest_handed)))\n",
    "lnds_stest = append_handedness(np.array(lnds_stest), stest_handed)\n",
    "labels_stest = list(map(lambda x: x[0], labels_stest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stest_preds = classifier_rl.predict(lnds_stest)\n",
    "cr = classification_report(labels_stest, stest_preds)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if model is only left or right handed\n",
    "\n",
    "Meaning, create two models: \n",
    "1. That understands signs done with a \"left\" hand\n",
    "2. And another that understands signs done with a \"right\" hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sign.training.load_data.StaticLandmarkLoader import StaticLandmarkLoader\n",
    "loader = StaticLandmarkLoader()\n",
    "td = loader.load_handed_training_data(file_path=\"../backend/model/handedness_keypoints_from_data.csv\")\n",
    "x_train, y_train, x_test, y_test, h_train, h_test = td\n",
    "\n",
    "def extract_hand_data(xs, ys, hs):\n",
    "    zipped = list(zip(xs, ys, hs))\n",
    "    lefts = list(filter(lambda x: x[2].lower() == \"left\", zipped))\n",
    "    rights = list(filter(lambda x: x[2].lower() == \"right\", zipped))\n",
    "    return zip(*lefts),zip(*rights)\n",
    "\n",
    "lefts, rights = extract_hand_data(x_train, y_train, h_train)\n",
    "x_l_train, y_l_train, _ = lefts\n",
    "x_r_train, y_r_train, _ = rights\n",
    "\n",
    "lefts_test, rights_test = extract_hand_data(x_test, y_test, h_test)\n",
    "x_l_test, y_l_test, _ = lefts_test\n",
    "x_r_test, y_r_test, _ = rights_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train a model on it.\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "ceof0 = 250\n",
    "degrees = 4\n",
    "C = 0.25\n",
    "\n",
    "cls_left = make_pipeline(StandardScaler(),\n",
    "                             SVC(kernel=\"poly\", degree=degrees, coef0=ceof0, C=C))\n",
    "cls_left.fit(x_l_train, y_l_train)\n",
    "\n",
    "cls_right = make_pipeline(StandardScaler(),\n",
    "                              SVC(kernel=\"poly\", degree=degrees, coef0=ceof0, C=C))\n",
    "cls_right.fit(x_r_train, y_r_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Classification report for left hand\n",
    "from sklearn.metrics import classification_report\n",
    "preds_left = cls_left.predict(x_l_test)\n",
    "print(classification_report(y_l_test, preds_left))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Classification report for right hand\n",
    "from sklearn.metrics import classification_report\n",
    "preds_right = cls_right.predict(x_r_test)\n",
    "print(classification_report(y_r_test, preds_right))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now the cursed homemade left or right hand data\n",
    "\n",
    "Test the MediaPipe left/right hand models on our own homemade data for 'U'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "lnds_stest, labels_stest = loader.load_test_data(\"bing_bong.csv\")\n",
    "stest_handed = np.array(list(map(lambda x: x.split(\"_\")[1].lower(),labels_stest)))\n",
    "labels_stest = list(map(lambda x: x[0], labels_stest))\n",
    "\n",
    "def filter_stest(lnds_stest, labels_stest, hands_stest, hand:str = \"\"):\n",
    "    zipped = zip(lnds_stest, labels_stest, hands_stest)\n",
    "    if hand:\n",
    "        return zip(*list(filter(lambda x: x[2].lower() == hand.lower() ,zipped)))\n",
    "    else:\n",
    "        return zip(*zipped)\n",
    "\n",
    "lnds_l_stest, labels_l_stest,_ = filter_stest(lnds_stest, labels_stest, stest_handed, \"LEFT\")\n",
    "lnds_r_stest, labels_r_stest,_ = filter_stest(lnds_stest, labels_stest, stest_handed, \"RIGHT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_left_scores = cls_left.decision_function([lnds_l_stest[5]])\n",
    "#T = 26\n",
    "#preds_left_stest = (y_left_scores > T)\n",
    "preds_left_stest = cls_left.predict(lnds_l_stest)\n",
    "print(classification_report(labels_l_stest, preds_left_stest))\n",
    "# res = []\n",
    "# for pred, klass in zip(*list(preds_left_stest), cls_left.classes_):\n",
    "#     if pred:\n",
    "#         res.append(klass)\n",
    "\n",
    "# f\"Predicted classes all below threshold {T}: {res}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "preds_right_stest = cls_right.predict(lnds_r_stest)\n",
    "print(classification_report(labels_r_stest, preds_right_stest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What if binary?\n",
    "\n",
    "Creating a binary classifier for a single class (ASL letter) that only handles signs done with the left hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def shuffleeee(data, label):\n",
    "    zipped = list(zip(data, label))\n",
    "    shuffle(zipped)\n",
    "    return list(zip(*zipped))\n",
    "\n",
    "def spliterino(data, labels):\n",
    "    \"\"\"Perform the test-train split...\"\"\"\n",
    "    zipped = list(zip(data,labels))\n",
    "    static_test_train, static_test_test = train_test_split(zipped, train_size=0.8, random_state=42)\n",
    "    train = list(zip(*static_test_train))\n",
    "    test = list(zip(*static_test_test))\n",
    "    return train[0], train[1], test[0], test[1]     #landmarks, labels, landmarks, labels\n",
    "\n",
    "homemade_train_x, homemade_train_labels, homemade_test_x, homemade_test_labels = spliterino(lnds_l_stest, labels_l_stest)\n",
    "\n",
    "# BEWARE: Here we also append our own homemade data to the training data.\n",
    "u_or_not_left_lnds = np.concatenate( (x_l_train, homemade_train_x), axis=0)\n",
    "u_or_not_left_labels = (np.concatenate( (y_l_train, homemade_train_labels), axis = 0) == \"U\")\n",
    "print(u_or_not_left_labels)\n",
    "\n",
    "clf_u_l = make_pipeline(StandardScaler(),\n",
    "                         SVC(kernel=\"poly\", degree=degrees, coef0=ceof0, C=C))\n",
    "clf_u_l.fit(*shuffleeee(u_or_not_left_lnds, u_or_not_left_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "u_x_l_stest = homemade_test_x\n",
    "u_y_l_stest = list(map(lambda _ : True, homemade_test_labels))\n",
    "print(len(u_y_l_stest), len(u_x_l_stest))\n",
    "\n",
    "preds_u_left_stest = clf_u_l.predict(u_x_l_stest)\n",
    "print(classification_report(u_y_l_stest, preds_u_left_stest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's demo it for ourselves!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from matplotlib import pyplot\n",
    "from sign.training.landmark_extraction.MediaPiper import MediaPiper\n",
    "from sign.landmarks import calc_landmark_list, pre_process_landmark\n",
    "import numpy as np\n",
    "\n",
    "mp = MediaPiper()\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "\n",
    "ret, frame = cap.read()\n",
    "\n",
    "img = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "img = cv.flip(img, 1)\n",
    "res = mp.process_image(img)\n",
    "print(res.multi_handedness)\n",
    "if res.multi_handedness:\n",
    "    print(f\"Found handedness: {res.multi_handedness[0].label}\")\n",
    "try:\n",
    "    if res.multi_hand_landmarks is not None:\n",
    "        landmarks = calc_landmark_list(res.multi_hand_landmarks)\n",
    "\n",
    "        # Conversion to relative coordinates / normalized coordinates\n",
    "        landmarks = pre_process_landmark(landmarks)\n",
    "\n",
    "        landmarks = np.array([landmarks], dtype=np.float32)    \n",
    "\n",
    "       # scores = cls_left.decision_function(landmarks)\n",
    "        #scores = (scores > 24)\n",
    "        #candidates = [(klass, score) for score,klass in zip(*scores, cls_left.classes_) if score]\n",
    "        #print(candidates)\n",
    "        #probs = cls_left.predict_proba(landmarks)\n",
    "        #print(probs)\n",
    "\n",
    "        # CAN CHANGE THE MODEL HERE: \n",
    "        predictions = clf_u_l.predict(landmarks)\n",
    "        # ^CAN CHANGE THE MODEL HERE\n",
    "        print(predictions)\n",
    "    else:\n",
    "        print(\"there's nothing broski\")\n",
    "finally:\n",
    "    pyplot.imshow(img)\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
