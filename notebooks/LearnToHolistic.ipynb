{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning To use the Bible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Holistic on an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from natsort import natsorted\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class ImageSequence:\n",
    "    id: int\n",
    "    filepaths: list[str]\n",
    "\n",
    "#Constants\n",
    "FRAMES_PATH = \"../backend/dynamic_signs/frames\"\n",
    "\n",
    "def __extract_prefix(filename:str, separator:str = \"_\"):\n",
    "    return filename.split(separator)[0]\n",
    "\n",
    "T_filepaths = list[str]\n",
    "def get_image_sequences_from_dir(dir:str) -> dict[str, list[ImageSequence]]:\n",
    "    labels = [folder for folder in os.listdir(dir)\n",
    "                  if os.path.isdir(dir + os.sep + folder)]\n",
    "    res_dict = {}\n",
    "    for label in labels:\n",
    "        folder_path = dir + os.sep + label + os.sep\n",
    "        files = natsorted([file for file in os.listdir(folder_path)\n",
    "                               if os.path.isfile(folder_path + file)])\n",
    "\n",
    "        prev_prefix = __extract_prefix(files[0])\n",
    "        cur_sequence = []\n",
    "        label_sequences: list[ImageSequence] = [ImageSequence(int(prev_prefix), cur_sequence)]\n",
    "        for image in files:\n",
    "            prefix = __extract_prefix(image)\n",
    "            if not (prefix == prev_prefix):\n",
    "                cur_sequence = []\n",
    "                label_sequences.append(ImageSequence(int(prefix), cur_sequence))\n",
    "            cur_sequence.append(folder_path + image)\n",
    "            prev_prefix = prefix\n",
    "        res_dict[label] = label_sequences\n",
    "    return res_dict\n",
    "\n",
    "# label_files_dict = get_image_sequences_from_dir(FRAMES_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, NamedTuple\n",
    "import mediapipe.python.solutions.holistic as mp_holistic\n",
    "import cv2 as cv\n",
    "import csv\n",
    "\n",
    "mp = mp_holistic.Holistic(\n",
    "    static_image_mode=True,\n",
    "    model_complexity=1,\n",
    ")\n",
    "\n",
    "def get_attributes_as_dict(obj : NamedTuple) -> dict[str, Any]:\n",
    "    return {field : getattr(obj, field) for field in obj._fields}\n",
    "\n",
    "def write_processed_sequence_to_csv(label:str, id: int, \n",
    "                                    mp_process_results: list[NamedTuple],\n",
    "                                    verbose = False):\n",
    "        with open(f\"{label}_out.csv\", 'a', newline=\"\") as f:        \n",
    "            writer = csv.writer(f)\n",
    "            for res in mp_process_results:\n",
    "                res_as_dict = get_attributes_as_dict(res)\n",
    "                #Sort to get:\n",
    "                # face_landmarks, left_hand_landmarks, pose_landmarks, pose_world_landmarks, right_hand_landmarks, segmentation_mask\n",
    "                for body_part, landmarks in sorted(res_as_dict.items(), key = lambda key_value : key_value[0]):\n",
    "                    toWrite = []\n",
    "                    which = body_part.removesuffix(\"_landmarks\")\n",
    "                    if landmarks is not None: \n",
    "                        toWrite = list(sum([ (mrk.x, mrk.y, mrk.z) for mrk in landmarks.landmark], ()))\n",
    "                    else:\n",
    "                        if verbose:\n",
    "                            print(f\"No landmarks for {which}\")\n",
    "                    writer.writerow([which, id, *toWrite])\n",
    "            \n",
    "            \n",
    "def write_to_csv(label_files_dict: dict[str, list[ImageSequence]]):\n",
    "    for label, img_sequences in label_files_dict.items():\n",
    "        for sequence in img_sequences:\n",
    "            results = [ mp.process(cv.imread(img_path)) for img_path in sequence.filepaths] \n",
    "            print(f\"MediaPipe for {label}-{sequence.id} has {len(results)} many elements\")\n",
    "            write_processed_sequence_to_csv(label, sequence.id, results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This extracts zippity zip zip\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "import shutil\n",
    "import cv2\n",
    "from zipfile import ZipFile\n",
    "\n",
    "from sign.training.landmark_extraction.MediaPiper import MediaPiper\n",
    "\n",
    "if False:\n",
    "    regex = r\".*\\/*(.+)\\/(.+)\\.avi\"\n",
    "    mediapiper = MediaPiper()\n",
    "    with ZipFile(str(Path.cwd().absolute().joinpath(\"data/zippo.zip\")), 'r') as myzip:\n",
    "        try:\n",
    "            for file in myzip.filelist:\n",
    "                match = re.match(regex, file.filename)\n",
    "                if match is not None:\n",
    "                    sign = match.group(1)\n",
    "                    id = match.group(2)\n",
    "                    video = myzip.open(file.filename).read()\n",
    "                    with open(\"video.avi\", \"wb\") as video_file:\n",
    "                        video_file.write(video)\n",
    "                    vc = cv2.VideoCapture('video.avi')\n",
    "                    i = 0\n",
    "                    if vc.isOpened():\n",
    "                        rval , frame = vc.read()\n",
    "                    else:\n",
    "                        rval = False\n",
    "                    path = f\"./dynamic_signs/frames\"\n",
    "                    path_sign = f\"{path}/{sign}\"\n",
    "                    if not os.path.exists(path):\n",
    "                        os.makedirs(path)\n",
    "                    if not os.path.exists(path_sign):\n",
    "                        os.makedirs(path_sign)   \n",
    "                    while rval:\n",
    "                        rval, frame = vc.read()\n",
    "                        if frame is None or frame.size == 0:\n",
    "                            continue\n",
    "                        cv2.imwrite(f\"{path_sign}/{id}_{i}.png\", frame)\n",
    "                        i = i + 1\n",
    "                    vc.release()\n",
    "                    label_files_dict = get_image_sequences_from_dir(path)\n",
    "\n",
    "                    print(label_files_dict)\n",
    "                    write_to_csv(label_files_dict)\n",
    "                    shutil.rmtree(path_sign)\n",
    "\n",
    "        finally:\n",
    "            os.remove(\"video.avi\")  # Clean up after ourselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "HolisticSequence = dict[str, list[float]]\n",
    "\n",
    "\n",
    "class HoslisticCsvReader:\n",
    "    @staticmethod\n",
    "    def spawn_sequence() -> HolisticSequence:\n",
    "        return {\"face\": [],\n",
    "                \"left_hand\": [],\n",
    "                \"pose\" : [],\n",
    "                \"right_hand\" : [],\n",
    "                }\n",
    "\n",
    "    def __init__(self, sequence_spawner = spawn_sequence):\n",
    "        self.new_holistic_sequence = sequence_spawner\n",
    "\n",
    "    def _avoid(self, row_val: str):\n",
    "        return row_val == \"segmentation_mask\" or row_val == \"pose_world\"\n",
    "    \n",
    "    def _remove_file_suffix(self, file_name: str):\n",
    "        return file_name.removesuffix(\"_out.csv\")\n",
    "\n",
    "    def extract_holistic_landmarks(self, path:Path) -> dict[int, HolisticSequence]:\n",
    "        res :dict[int, HolisticSequence] = {}\n",
    "        with open(path, 'r') as f:\n",
    "            reader = csv.reader(f)\n",
    "            prev_id = -1\n",
    "\n",
    "            cur_entry: HolisticSequence = self.new_holistic_sequence()\n",
    "            for row in reader:\n",
    "                row_key = row[0]\n",
    "                if self._avoid(row_key):\n",
    "                    continue\n",
    "\n",
    "                new_id = int(row[1])\n",
    "                is_new_video = new_id != prev_id\n",
    "                if is_new_video and prev_id != -1:\n",
    "                    res[prev_id] = cur_entry\n",
    "                    cur_entry = self.new_holistic_sequence()\n",
    "                    \n",
    "                prev_id = new_id\n",
    "                if len(row) > 2:\n",
    "                    landmarks = row[2:]\n",
    "                    row_marks = list(map(lambda elm : float(elm), landmarks))\n",
    "                    if row_key not in cur_entry:\n",
    "                        raise ValueError(f\"Holistic Sequence only allows keys: {[k for k in self.new_holistic_sequence().keys()]}.\\n\\tEither update \\\"spawn_sequence\\\" function or check if csv is broken\")\n",
    "                    cur_entry[row_key].extend( row_marks)\n",
    "            if len(list(cur_entry.values())[0]) > 0:\n",
    "                res[prev_id] = cur_entry\n",
    "        return res\n",
    "    \n",
    "    def extract_holistic_landmarks_from_folder(self, path: str) -> dict[str, dict[int, HolisticSequence]]:\n",
    "        \"\"\"\n",
    "            Returns a dictionary from LABEL of the sign to a dictionary of sequence_ID to a HolisticSequence.\n",
    "                \n",
    "                HolisticSequence:\n",
    "                    A dictionary of keys: [\"face\", \"right_hand\", \"left_hand\", \"pose\"]. \n",
    "                    Keys map to a list of the floats corresponding to xyz of landmarks of all frames in the sequnce.\n",
    "        \"\"\"\n",
    "        res = {}\n",
    "        for csv_file in [path+os.sep+file for file in os.listdir(path) if file.endswith(\".csv\")]:\n",
    "            path_to_file = Path(csv_file)\n",
    "            label = self._remove_file_suffix(path_to_file.name)\n",
    "            res[label] = self.extract_holistic_landmarks(path_to_file.absolute())\n",
    "        return res\n",
    "\n",
    "reader = HoslisticCsvReader()\n",
    "result = reader.extract_holistic_landmarks_from_folder(\".\")\n",
    "f\"Parsed {result} classes\"\n",
    "len(result[\"J\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BORROW FROM DYNAMIC GESTURE\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "from typing import Iterable, Tuple, TypeVar\n",
    "from sign.trajectory import TrajectoryBuilder\n",
    "from sign.landmarks import NormalizedLandmark, pre_process_landmark, calc_landmark_list\n",
    "from dynamic_signs.csv_reader import csv_reader\n",
    "from sklearn.model_selection import train_test_split\n",
    "bob = TrajectoryBuilder(target_len=24)\n",
    "\n",
    "\n",
    "def shuffle_training_data(data: Iterable, labels: Iterable) -> Tuple[Iterable,Iterable]:\n",
    "    zipped = list(zip(data, labels))\n",
    "    shuffle(zipped)\n",
    "    return tuple(zip(*zipped))\n",
    "    \n",
    "\n",
    "def extract_training_data_and_labels_from_dynamic_gesture_map(gesture_map: dict[str, list[np.ndarray]]) -> Tuple[Iterable[np.ndarray], Iterable[str]]:\n",
    "    trajectories_and_landmarks: list[np.ndarray] = []\n",
    "    labels : list[str] = []\n",
    "    for label, label_data in gesture_map.items():\n",
    "        for data in label_data:\n",
    "            labels.append(label)\n",
    "            trajectories_and_landmarks.append(data)\n",
    "    return shuffle_training_data(trajectories_and_landmarks, labels)\n",
    "\n",
    "def prune_training_data_and_labels_from_dynamic_gesture_csv(input: dict[str, dict[int, list[float]]]) -> dict[str, list[np.ndarray]]:\n",
    "    target_length = 24*3*21\n",
    "    bob = TrajectoryBuilder(target_len=target_length)\n",
    "    res: dict[str, list[np.ndarray]] = {}\n",
    "    for label, videos in input.items():\n",
    "        for id, frames in videos.items():\n",
    "            if len(frames) == 0:\n",
    "                print(f\"{label}-{id} is empty - SKIPPING\")\n",
    "                continue\n",
    "            existing = res.get(label)\n",
    "            if len(frames) < target_length:\n",
    "                frames = bob.pad_sequences_of_landmarks(frames)\n",
    "            else: \n",
    "                frames = bob.extract_keyframes_sample(frames)\n",
    "            frames = np.array(frames)\n",
    "            if existing is not None:\n",
    "                existing.append(frames)\n",
    "            else:\n",
    "                res[label] = [frames]\n",
    "                \n",
    "    return res\n",
    "\n",
    "def extract_left_hand_landmarks_from_holistic(dict: dict[str, dict[int, HolisticSequence]]) -> dict[str, dict[int, list[float]]]:\n",
    "    res = {}\n",
    "    for label, video_id_to_holistic_seq in dict.items():\n",
    "        res[label] = {} \n",
    "        for id, holy_seq in video_id_to_holistic_seq.items():\n",
    "            if len(holy_seq[\"left_hand\"]) > 0:\n",
    "                res[label][id] = holy_seq[\"left_hand\"]\n",
    "            elif len(holy_seq[\"right_hand\"]) > 0:\n",
    "                res[label][id] = holy_seq[\"right_hand\"]\n",
    "            #else --> Do nothing!!??\n",
    "            \n",
    "    return res\n",
    "\n",
    "def extract_training_data_and_labels_from_dynamic_gesture_csv() -> Tuple[Iterable[np.ndarray], Iterable[str]]:\n",
    "    unpruned = reader.extract_holistic_landmarks_from_folder(\".\")\n",
    "    unpruned = extract_left_hand_landmarks_from_holistic(unpruned)\n",
    "    pruned = prune_training_data_and_labels_from_dynamic_gesture_csv(unpruned)\n",
    "    normalized_landmarks = {}\n",
    "    \n",
    "    for key, val in pruned.items():\n",
    "        for seq in val:\n",
    "            trajectory = bob.make_trajectory(seq.reshape(-1, 21, 3))\n",
    "            landmarks = []\n",
    "            for i in range(0, len(seq), 3):\n",
    "                landmark = NormalizedLandmark()\n",
    "                landmark.x = seq[i]\n",
    "                landmark.y = seq[i+1]\n",
    "                landmark.z = seq[i+2]\n",
    "                landmarks.append(landmark)\n",
    "            normalized_landmarks_for_video = pre_process_landmark(calc_landmark_list(landmarks))\n",
    "            existing = normalized_landmarks.get(key)\n",
    "            asd = trajectory.to_float_list()\n",
    "            asd.extend(normalized_landmarks_for_video)\n",
    "            with_trajectories = np.array(asd)\n",
    "            \n",
    "            if existing is None:\n",
    "                normalized_landmarks[key] = [with_trajectories]\n",
    "            else:\n",
    "                existing.append(with_trajectories)\n",
    "    return extract_training_data_and_labels_from_dynamic_gesture_map(normalized_landmarks)\n",
    "\n",
    "extracted_data,extracted_labels = extract_training_data_and_labels_from_dynamic_gesture_csv()\n",
    "\n",
    "shapes = list(map(lambda arr : arr.shape ,extracted_data))\n",
    "first = extracted_data[0].shape\n",
    "f\"Shape of first {first}. Do all data have this shape? '{'Yes' if all(first == s for s in shapes) else 'No'}'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Holistic on one-armed-bandit looking for hands- Holy nation approves of this one \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "labels_J = (np.array(extracted_labels, dtype=np.str_) == \"J\")\n",
    "model_J_or_not = make_pipeline(StandardScaler(),\n",
    "                          SVC(kernel=\"poly\", degree=6, coef0=1))\n",
    "model_J_or_not.fit(extracted_data, labels_J)\n",
    "\n",
    "if False:\n",
    "    from joblib import dump\n",
    "    dump(model_svm, 'dynamic_model.joblib')\n",
    "model_J_or_not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ABSOLUTE WORST TEST, please correct me :3\n",
    "toPredict = [extracted_data[0]]\n",
    "true_label = labels_J[0]\n",
    "print(f\"Is J?\\n  Predicted: {model_J_or_not.predict(toPredict)[0]}\\n  Should be: {true_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
